{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Title to be decided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is the file for the code of our group assignment. Under development.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data from External File\n",
    "\n",
    "Read data in external files. For convenience, the original `.pcapng` file has been converted into `.json` and `.csv` with Wireshark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10625 packets read\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_index': 'packets-XXXX-XX-XX',\n",
       " '_type': 'doc',\n",
       " '_score': None,\n",
       " '_source': {'layers': {'pkt_comment': {'frame.comment': '13682128230572000042,china',\n",
       "    'frame.comment_tree': {'_ws.expert': {'frame.comment.expert': '',\n",
       "      '_ws.expert.message': '13682128230572000042,china',\n",
       "      '_ws.expert.severity': '1048576',\n",
       "      '_ws.expert.group': '184549376'}}},\n",
       "   'frame': {'frame.interface_id': '0',\n",
       "    'frame.interface_id_tree': {'frame.interface_name': 'unknown'},\n",
       "    'frame.encap_type': '7',\n",
       "    'frame.time': 'Not representable',\n",
       "    'frame.offset_shift': '0.000000000',\n",
       "    'frame.time_epoch': '-1460980371.753735000',\n",
       "    'frame.time_delta': '0.000000000',\n",
       "    'frame.time_delta_displayed': '0.000000000',\n",
       "    'frame.time_relative': '0.000000000',\n",
       "    'frame.number': '1',\n",
       "    'frame.len': '58',\n",
       "    'frame.cap_len': '58',\n",
       "    'frame.marked': '0',\n",
       "    'frame.ignored': '0',\n",
       "    'frame.protocols': 'raw:ip:udp:dns',\n",
       "    'frame.coloring_rule.name': 'UDP',\n",
       "    'frame.coloring_rule.string': 'udp'},\n",
       "   'raw': 'Raw packet data',\n",
       "   'ip': {'ip.version': '4',\n",
       "    'ip.hdr_len': '20',\n",
       "    'ip.dsfield': '0x00000000',\n",
       "    'ip.dsfield_tree': {'ip.dsfield.dscp': '0', 'ip.dsfield.ecn': '0'},\n",
       "    'ip.len': '58',\n",
       "    'ip.id': '0x00002baf',\n",
       "    'ip.flags': '0x00000000',\n",
       "    'ip.flags_tree': {'ip.flags.rb': '0',\n",
       "     'ip.flags.df': '0',\n",
       "     'ip.flags.mf': '0'},\n",
       "    'ip.frag_offset': '0',\n",
       "    'ip.ttl': '254',\n",
       "    'ip.proto': '17',\n",
       "    'ip.checksum': '0x000075e6',\n",
       "    'ip.checksum.status': '2',\n",
       "    'ip.src': '10.11.1.3',\n",
       "    'ip.addr': '8.8.8.8',\n",
       "    'ip.src_host': '10.11.1.3',\n",
       "    'ip.host': 'dns.google',\n",
       "    'ip.dst': '8.8.8.8',\n",
       "    'ip.dst_host': 'dns.google'},\n",
       "   'udp': {'udp.srcport': '57329',\n",
       "    'udp.dstport': '53',\n",
       "    'udp.port': '53',\n",
       "    'udp.length': '38',\n",
       "    'udp.checksum': '0x000074d0',\n",
       "    'udp.checksum.status': '2',\n",
       "    'udp.stream': '0',\n",
       "    'Timestamps': {'udp.time_relative': '0.000000000',\n",
       "     'udp.time_delta': '0.000000000'}},\n",
       "   'dns': {'dns.id': '0x0000e8e9',\n",
       "    'dns.flags': '0x00000100',\n",
       "    'dns.flags_tree': {'dns.flags.response': '0',\n",
       "     'dns.flags.opcode': '0',\n",
       "     'dns.flags.truncated': '0',\n",
       "     'dns.flags.recdesired': '1',\n",
       "     'dns.flags.z': '0',\n",
       "     'dns.flags.checkdisable': '0'},\n",
       "    'dns.count.queries': '1',\n",
       "    'dns.count.answers': '0',\n",
       "    'dns.count.auth_rr': '0',\n",
       "    'dns.count.add_rr': '0',\n",
       "    'Queries': {'lcs.naver.jp: type A, class IN': {'dns.qry.name': 'lcs.naver.jp',\n",
       "      'dns.qry.name.len': '12',\n",
       "      'dns.count.labels': '3',\n",
       "      'dns.qry.type': '1',\n",
       "      'dns.qry.class': '0x00000001'}},\n",
       "    'dns.response_in': '2'}}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON including all details of packets\n",
    "#   errors=\"surrogateescape\" to pass the encoding errors raised by contents in HTTP packets\n",
    "with open(\"./data/traffic.json\", \"r\", encoding=\"utf-8\", errors=\"surrogateescape\") as f:\n",
    "    dataset_json=json.load(f)\n",
    "    print(f\"{len(dataset_json)} packets read\")\n",
    "\n",
    "# print one for checking\n",
    "dataset_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: UNUSED - REMOVE LATER\n",
    "# # Read the CSV\n",
    "# # TODO: Info in CSV should be covered by the one in JSON.\n",
    "# #       Remove it in the future if not used\n",
    "# dataset_csv=pd.read_csv(\"./data/traffic.csv\")\n",
    "\n",
    "# dataset_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extract dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels include ['china' 'india' 'us']\n",
      "(10625,)\n"
     ]
    }
   ],
   "source": [
    "# Extract labels(y) from JSON\n",
    "dataset_y = np.array(list(map(\n",
    "    lambda packet_json: (packet_json[\"_source\"][\"layers\"][\"pkt_comment\"][\"frame.comment\"]).split(\",\")[1], \n",
    "    dataset_json\n",
    ")))\n",
    "\n",
    "print(f\"Labels include {np.unique(dataset_y)}\")\n",
    "print(dataset_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.11.1.3\n",
      "10.11.1.3\n",
      "8.8.8.8\n",
      "dns.google\n"
     ]
    }
   ],
   "source": [
    "# Extract source IP, source IP host, destination IP and destination IP host from dataset\n",
    "dataset_X_ip_src = np.array(list(map(\n",
    "    lambda packet_json: packet_json[\"_source\"][\"layers\"][\"ip\"][\"ip.src\"], \n",
    "    dataset_json\n",
    ")))\n",
    "dataset_X_ip_src_host = np.array(list(map(\n",
    "    lambda packet_json: packet_json[\"_source\"][\"layers\"][\"ip\"][\"ip.src_host\"], \n",
    "    dataset_json\n",
    ")))\n",
    "dataset_X_ip_dst = np.array(list(map(\n",
    "    lambda packet_json: packet_json[\"_source\"][\"layers\"][\"ip\"][\"ip.dst\"], \n",
    "    dataset_json\n",
    ")))\n",
    "dataset_X_ip_dst_host = np.array(list(map(\n",
    "    lambda packet_json: packet_json[\"_source\"][\"layers\"][\"ip\"][\"ip.dst_host\"], \n",
    "    dataset_json\n",
    ")))\n",
    "\n",
    "# print first ones for checking\n",
    "print(dataset_X_ip_src[0])\n",
    "print(dataset_X_ip_src_host[0])\n",
    "print(dataset_X_ip_dst[0])\n",
    "print(dataset_X_ip_dst_host[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check data sanity and deal with missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source/dest IP not an IPv4 address:\n",
      "[]\n",
      "[]\n",
      "Source/dest host not an IPv4 nor a domain:\n",
      "[]\n",
      "['no-data', 'no-data']\n",
      "\n",
      "Indexes of rows with missing 'dst.host': [960 964]\n",
      "Missing 'dst.host' filled\n"
     ]
    }
   ],
   "source": [
    "# Data sanity check\n",
    "pattern_not_ipv4 = re.compile(r\"(?!((\\b25[0-5]|\\b2[0-4][0-9]|\\b[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}))\")\n",
    "pattern_not_ipv4_nor_domain = re.compile(r\"(?!(((\\b25[0-5]|\\b2[0-4][0-9]|\\b[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}))|[-_0-9a-zA-Z]+\\.[-_0-9a-zA-Z]+)\")\n",
    "\n",
    "print(\"Source/dest IP not an IPv4 address:\")\n",
    "print(list(filter(pattern_not_ipv4.match, dataset_X_ip_src)))\n",
    "print(list(filter(pattern_not_ipv4.match, dataset_X_ip_dst)))\n",
    "print(\"Source/dest host not an IPv4 nor a domain:\")\n",
    "print(list(filter(pattern_not_ipv4_nor_domain.match, dataset_X_ip_src_host)))\n",
    "print(list(filter(pattern_not_ipv4_nor_domain.match, dataset_X_ip_dst_host)))\n",
    "\n",
    "print()\n",
    "\n",
    "# Fill the missing `dst.host`\n",
    "#\n",
    "# Find \"no-data\" rows\n",
    "missing_dst_host_indexes = np.where(dataset_X_ip_dst_host=='no-data')[0]\n",
    "print(f\"Indexes of rows with missing 'dst.host': {missing_dst_host_indexes}\")\n",
    "\n",
    "# Fill the field with the IP address in `dst`, following the way of other rows\n",
    "for i in missing_dst_host_indexes:\n",
    "    dataset_X_ip_dst_host[i] = dataset_X_ip_dst[i]\n",
    "\n",
    "print(\"Missing 'dst.host' filled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bi-gram for similarity between IPs and domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10625, 1402)\n",
      "(10625, 867)\n",
      "(10625, 1629)\n",
      "(10625, 1059)\n",
      "\n",
      "(10625, 4957)\n"
     ]
    }
   ],
   "source": [
    "# bi-gram for similar IP and hostnames\n",
    "bigram_vec = CountVectorizer(ngram_range=(2, 2), token_pattern=r\"(?u)[^.]+\")\n",
    "dataset_X_ip_src_bg = bigram_vec.fit_transform(dataset_X_ip_src).toarray()\n",
    "dataset_X_ip_src_host_bg = bigram_vec.fit_transform(dataset_X_ip_src_host).toarray()\n",
    "dataset_X_ip_dst_bg = bigram_vec.fit_transform(dataset_X_ip_dst).toarray()\n",
    "dataset_X_ip_dst_host_bg = bigram_vec.fit_transform(dataset_X_ip_dst_host).toarray()\n",
    "\n",
    "print(dataset_X_ip_src_bg.shape)\n",
    "print(dataset_X_ip_src_host_bg.shape)\n",
    "print(dataset_X_ip_dst_bg.shape)\n",
    "print(dataset_X_ip_dst_host_bg.shape)\n",
    "\n",
    "dataset_X = np.concatenate((\n",
    "    dataset_X_ip_src_bg, \n",
    "    dataset_X_ip_src_host_bg,\n",
    "    dataset_X_ip_dst_bg, \n",
    "    dataset_X_ip_dst_host_bg), axis=1)\n",
    "\n",
    "print(\"\")\n",
    "print(dataset_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10625, 4957)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "dataset_X = MinMaxScaler().fit_transform(dataset_X)\n",
    "print(dataset_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA - check the 95% with figure\n",
    "# pca = PCA()\n",
    "# pca.fit(dataset_X)\n",
    "# pca_cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.axis([0, dataset_X.shape[1], 0, 1]) \n",
    "# plt.plot(pca_cumsum)\n",
    "# plt.axhline(y=0.95,color='red')\n",
    "# plt.xlabel(\"dimensions\")\n",
    "# plt.ylabel(\"explained variance\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10625, 650)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA for compression\n",
    "pca = PCA(n_components=0.95)\n",
    "dataset_X = pca.fit_transform(dataset_X)\n",
    "\n",
    "print(dataset_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7968, 650)\n",
      "(7968,)\n",
      "(2657, 650)\n",
      "(2657,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training set and testing set\n",
    "train_X, test_X, train_y, test_y = train_test_split(dataset_X, dataset_y, random_state=12345)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.X kNN classification as an example for using the processed dataset\n",
    "\n",
    "(And for checking the preprocess performance at the early stage)\n",
    "\n",
    "TODO: REMOVE BEFORE FINAL SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yqmtf/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:189: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# kNN classification test\n",
    "#\n",
    "# TODO: A brief test for evaluating performance during writing preprocessin code, \n",
    "#       gonna be removed later\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {knn.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "### 3.1 Logistic Regression\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7968, 650)\n",
      "(7968,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "LR = LogisticRegression()\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "#predict_results=LR.predict(test_X)\n",
    "#print(accuracy_score(predict_results, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Support Vector Machine (SVM)\n",
    "\n",
    "Implementing a kernelized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8965\n"
     ]
    }
   ],
   "source": [
    "#For the linear kernel (kernel_type='linear') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "SVM_linear = SVC(kernel='linear') \n",
    "SVM_linear.fit(train_X, train_y)\n",
    "predict_results=SVM_linear.predict(test_X)\n",
    "print(f\"Accuracy on test set: {accuracy_score(predict_results, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8991\n"
     ]
    }
   ],
   "source": [
    "#For the radial basis function kernel (kernel_type='rbf') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_rbf = SVC(kernel='rbf')  \n",
    "SVM_rbf.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_rbf.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8995\n"
     ]
    }
   ],
   "source": [
    "#For the polynomial kernel (kernel_type='poly') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_poly = SVC(kernel='poly') \n",
    "SVM_poly.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_poly.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9037\n"
     ]
    }
   ],
   "source": [
    "#For the polynomial kernel (kernel_type='poly') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_poly = SVC(C=1, kernel='poly', gamma=20, decision_function_shape='ovr')\n",
    "SVM_poly.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_poly.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8946\n"
     ]
    }
   ],
   "source": [
    "#For the radial basis function kernel (kernel_type='rbf') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_rbf_gamma = SVC(C=1, kernel='rbf', gamma=10, decision_function_shape='ovr')\n",
    "SVM_rbf_gamma.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_rbf_gamma.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7347\n"
     ]
    }
   ],
   "source": [
    "#For the radial basis function kernel (kernel_type='rbf') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_rbf_modify = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto',\n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None,\n",
    "                 verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "SVM_rbf_modify.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_rbf_modify.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.3801\n"
     ]
    }
   ],
   "source": [
    "#For the sigmoid function kernel (kernel_type='sigmoid') svm\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "SVM_sig = SVC(C=1, kernel='sigmoid', gamma=10, decision_function_shape='ovr')\n",
    "SVM_sig.fit(train_X, train_y)\n",
    "print(f\"Accuracy on test set: {SVM_sig.score(test_X, test_y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (?) neural network\n",
    "\n",
    "Maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Testing and Comparison\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
